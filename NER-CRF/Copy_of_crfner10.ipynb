{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading conll2003: <urlopen error [WinError 10060] A\n",
            "[nltk_data]     connection attempt failed because the connected party\n",
            "[nltk_data]     did not properly respond after a period of time, or\n",
            "[nltk_data]     established connection failed because connected host\n",
            "[nltk_data]     has failed to respond>\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'conll2003' from 'nltk.corpus' (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\corpus\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32md:\\Semester-7\\NLP\\CASE_STUDY_ALL_FILES\\NER-CRF\\Copy_of_crfner10.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semester-7/NLP/CASE_STUDY_ALL_FILES/NER-CRF/Copy_of_crfner10.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Download the CoNLL 2003 NER dataset (if not downloaded)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semester-7/NLP/CASE_STUDY_ALL_FILES/NER-CRF/Copy_of_crfner10.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mconll2003\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Semester-7/NLP/CASE_STUDY_ALL_FILES/NER-CRF/Copy_of_crfner10.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m conll2003\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semester-7/NLP/CASE_STUDY_ALL_FILES/NER-CRF/Copy_of_crfner10.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Load the CoNLL 2003 NER dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semester-7/NLP/CASE_STUDY_ALL_FILES/NER-CRF/Copy_of_crfner10.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m sentences \u001b[39m=\u001b[39m conll2003\u001b[39m.\u001b[39msents()\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'conll2003' from 'nltk.corpus' (c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\corpus\\__init__.py)"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the CoNLL 2003 NER dataset (if not downloaded)\n",
        "nltk.download('conll2003')\n",
        "\n",
        "from nltk.corpus import conll2003\n",
        "\n",
        "# Load the CoNLL 2003 NER dataset\n",
        "sentences = conll2003.sents()\n",
        "ne_chunks = conll2003.iob_sents()\n",
        "\n",
        "# Accessing sentences and named entity chunks\n",
        "for i in range(5):  # Print the first 5 sentences and named entity chunks\n",
        "    print(f\"Sentence {i + 1}: {sentences[i]}\")\n",
        "    print(f\"Named Entities {i + 1}: {ne_chunks[i]}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gWcaUnokarq",
        "outputId": "7b36948d-12dc-47a6-8b19-e7cb61be7642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.3.6)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn_crfsuite) (0.9.9)\n",
            "Requirement already satisfied: tabulate in c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn_crfsuite) (0.9.0)\n",
            "Requirement already satisfied: six in c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn_crfsuite) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from sklearn_crfsuite) (4.66.1)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm>=2.0->sklearn_crfsuite) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 23.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\users\\admin\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn_crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9NfK3WIkKh86"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XVckJxFBKmlA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_json(\"./ta_test.json\", lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9y_O1SILng_",
        "outputId": "27495089-b403-45b2-91bc-cc70bb6ea87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 758 entries, 0 to 757\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   words   758 non-null    object\n",
            " 1   ner     758 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 12.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSS2xejSMxkS",
        "outputId": "c14e2037-1258-4ed0-afd2-5bfa30cde087"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "words  ner  \n",
              "False  False    758\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_N_kA4w5LtYB"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "for _, row in df.iterrows():\n",
        "    dataset.append(list(zip(row[\"words\"], row[\"ner\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V1tSb6wMTFh",
        "outputId": "df06a628-33ee-482b-f4b8-eac8f08cf5cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('மாதவரம்', 'B-LOC'), (',', 'O'), ('திருவொற்றியூர்', 'B-LOC')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFwPoId427HB",
        "outputId": "882c7e01-882c-4e12-eb09-28d1a9464b95"
      },
      "outputs": [],
      "source": [
        "import sklearn_crfsuite\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "def extract_features(sentence, index):\n",
        "    word, ner_tag = sentence[index]\n",
        "    \n",
        "    return {\n",
        "        'word': word,\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'prefix-1': \"\" if not word else word[0],\n",
        "        'prefix-2': word[:2],\n",
        "        'prefix-3': word[:3],\n",
        "        'prefix-4': word[:4],\n",
        "        'suffix-1': \"\" if not word else word[-1],\n",
        "        'suffix-2': word[-2:],\n",
        "        'suffix-3': word[-3:],\n",
        "        'suffix-4': word[-4:],\n",
        "        'prev_word': '' if index == 0 else sentence[index - 1][0],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1][0],\n",
        "        'has_hyphen': '-' in word,\n",
        "        'is_numeric': word.isdigit(),\n",
        "\n",
        "    }\n",
        "\n",
        "def sent2features(sent):\n",
        "    tmp = []\n",
        "    for i in range(len(sent)):\n",
        "        tmp.append(extract_features(sent, i))\n",
        "    return tmp\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for _, label in sent]\n",
        "\n",
        "# Extract features and labels from the training and testing sets\n",
        "X_train = [sent2features(sent) for sent in train_data]\n",
        "y_train = [sent2labels(sent) for sent in train_data]\n",
        "X_test = [sent2features(sent) for sent in test_data]\n",
        "y_test = [sent2labels(sent) for sent in test_data]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the CRF model\n",
        "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
        "                           c1=0.1,\n",
        "                           c2=0.1,\n",
        "                           max_iterations=100,\n",
        "                           all_possible_transitions=True)\n",
        "\n",
        "# Train the CRF model\n",
        "try:\n",
        "    crf.fit(X_train, y_train)\n",
        "except AttributeError:\n",
        "    print(\"ok\")\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('ner_crf_model.pkl', 'wb') as file:\n",
        "    pickle.dump(crf, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = crf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## Penn ##\n",
            "F1 score on Test Data\n",
            "0.8425170088639261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 score on Training Data \n",
            "0.998345072631972\n"
          ]
        }
      ],
      "source": [
        "from sklearn_crfsuite import metrics\n",
        "from sklearn_crfsuite import scorers\n",
        "print(\"## Penn ##\")\n",
        "\n",
        "#First calculate a prediction from test data, then we print the metrics for f-1 using the .flat_f1_score method.\n",
        "y_pred=crf.predict(X_test)\n",
        "print(\"F1 score on Test Data\")\n",
        "print(metrics.flat_f1_score(y_test, y_pred,average='weighted',labels=crf.classes_))\n",
        "#For the sake of clarification, we do the same for train data.\n",
        "y_pred_train=crf.predict(X_train)\n",
        "print(\"F1 score on Training Data \")\n",
        "print(metrics.flat_f1_score(y_train, y_pred_train,average='weighted',labels=crf.classes_))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
